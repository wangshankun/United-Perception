num_classes: &num_classes 81

runtime:
  rank_init: true
  runner:
    type: quant
  task_names: quant_det
quant:
  quant_type: ptq
  deploy_backend: academic
  cali_batch_size: 8 # 256 / 4(bs) / n(gpus) 
  tricks:
    special: [backbone.layer0.0]
    bit: 8
  ptq:
    pattern: block # layer for ada, block for brecq/qdrop
    scale_lr: 4.0e-5
    warm_up: 0.25
    weight: 0.005
    max_count: 20000
    b_range: [20, 2]
    keep_gpu: false
    round_mode: learned_hard_sigmoid
    prob: 0.5 # 1. for brecq/ada, 0.5 for qdrop
  prepare_args:
    extra_qconfig_dict:
      w_observer: MSEObserver
      a_observer: EMAMSEObserver
      a_fakequantize: QDropFakeQuantize
      w_fakequantize: AdaRoundFakeQuantize
      w_qscheme:
        bit: 4
        symmetry: false
        per_channel: false
        pot_scale: false
        p: 2.4
      a_qscheme:
        bit: 4
        symmetry: false
        per_channel: false
        pot_scale: false
        p: 2.4
    leaf_module: [Space2Depth, FrozenBatchNorm2d]
    extra_quantizer_dict:
      additional_module_type: [ConvFreezebn2d, ConvFreezebnReLU2d]

## SSD input is fix 300*300
#resize:
#  type: keep_ar_resize
#  kwargs:
#    scales: [120, 150, 180, 210, 240, 270]
#    max_size: 300
#    separate_wh: true

#test_resize: &test_resize
#  type: keep_ar_resize
#  kwargs:
#    scales: [300]
#    max_size: 300
#    separate_wh: true

fix_output_resize: &fix_output_resize
  type: fix_output_resize
  kwargs:
    scales: [300, 300]
    max_size: 320

expand: &stitch_expand
  type: stitch_expand
  kwargs:
    expand_ratios: 2.0
    expand_prob: 0.5

crop: &crop
  type: crop
  kwargs:
    means: [123.675, 116.280, 103.530]
    scale: 300
    crop_prob: 0.5

color_jitter: &color_jitter
  type: color_jitter
  kwargs:
    brightness: 32
    contrast: [0.5, 1.5]
    saturation: [0.5, 1.5]
    hue: 18

to_tensor: &to_tensor
  type: to_tensor

normalize: &normalize
  type: normalize
  kwargs:
    mean: [0.485, 0.456, 0.406] # ImageNet pretrained statics
    std: [0.229, 0.224, 0.225]

dataset: # Required.
  train:
    dataset:
      type: coco
      kwargs:
        meta_file: /root/coco/annotations/instances_train2017.json
        image_reader:
          type: fs_opencv
          kwargs:
            image_dir: /root/coco/train2017
            color_mode: RGB
        transformer: [*fix_output_resize, *to_tensor, *normalize]
  test:
    dataset:
      type: coco
      kwargs:
        meta_file: /root/coco/annotations/instances_val2017.json
        image_reader:
          type: fs_opencv
          kwargs:
            image_dir: /root/coco/val2017
            color_mode: RGB
        transformer: [*fix_output_resize, *to_tensor, *normalize]
        evaluator:
          type: COCO               # choices = {'COCO', 'VOC', 'MR'}
          kwargs:
            gt_file: /root/coco/annotations/instances_val2017.json
            iou_types: [bbox]
  batch_sampler:
    type: aspect_ratio_group
    kwargs:
      sampler:
        type: dist
        kwargs: {}
      batch_size: 4
      aspect_grouping: [1]
  dataloader:
    type: base
    kwargs:
      num_workers: 4
      alignment: 32
      pin_memory: true


trainer: # Required.
  max_epoch: 6             # total epochs for the training
  test_freq: 1
  save_freq: 1
  optimizer:                 # optimizer = SGD(params,lr=0.001,momentum=0.9,weight_decay=0.0001)
    type: SGD
    kwargs:
      lr: 0.00000625
      momentum: 0.9
      weight_decay: 0.0
  lr_scheduler:              # lr_scheduler = MultStepLR(optimizer, milestones=[9,14],gamma=0.1)
    warmup_epochs: 0        # set to be 0 to disable warmup. When warmup,  target_lr = init_lr * total_batch_size
    warmup_type: linear
    warmup_ratio: 0.001
    type: MultiStepLR
    kwargs:
      milestones: [2, 4]     # epochs to decay lr
      gamma: 0.1             # decay rate

saver: # Required.
  save_dir: /root/save_dir/ret18_quant    # dir to save checkpoints
  #pretrain_model: /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth 
  pretrain_model: /root/save_dir/ret18/ckpt_e100.pth
  results_dir: /root/results_dir/ret18_quant  # dir to save detection results. i.e., bboxes, masks, keypoints
  auto_resume: false  # find last checkpoint from save_dir and resume from it automatically
                     # this option has the highest priority (auto_resume > opts > resume_model > pretrain_model)


hooks:
- type: auto_checkpoint

net:
- name: backbone               
  type: resnet18
  kwargs:
    frozen_layers: [0, 1]      # layer0...1 is fixed
    out_layers: [2, 3, 4]       # layer2...4, commonly named Conv3...5
    out_strides: [8, 16, 32]    # tell the strides of output features
    normalize:
      type: mqbench_freeze_bn
    initializer:
      method: msra
- name: neck
  prev: backbone
  type: SSDNeck
  kwargs:
    outplanes: [128, 256, 512, 512, 256, 256]
    out_strides: [8, 16, 32, 64, 100, 300]
    extern_level: 3
    extern_outplanes: [256, 'S', 512, 128, 'S', 256, 128, 256]
    initializer:
      method: xavier
    normalize:
      type: mqbench_freeze_bn
- name: roi_head
  prev: neck
  type: SSDHeader
  kwargs:
    inplanes: [128, 256, 512, 512, 256, 256]
    num_classes: *num_classes
    initializer:
      method: normal
      std: 0.01
    num_anchors: [4, 6, 6, 6, 4, 4]
    num_level: 6
    normalize:
      type: mqbench_freeze_bn
- name: post_process
  prev: roi_head
  type: ssd_post
  kwargs:
    num_classes: *num_classes
    cfg:
      cls_loss:
        type: quality_focal_loss
        kwargs:
          gamma: 2.0
      loc_loss:
        type: iou_loss
        kwargs:
          loss_type: giou
          loss_weight: 1.0
      anchor_generator:
        type: ssd_anchor
        kwargs:
          ratios: [[2], [2, 3], [2, 3], [2, 3], [2], [2]] 
          strides: [8, 16, 32, 64, 100, 300]
      roi_supervisor:
        type: atss
        kwargs:
          top_n: 18
      roi_predictor:
        type: base
        kwargs:
          pre_nms_score_thresh: 0.05    # to reduce computation
          pre_nms_top_n: 1000
          post_nms_top_n: 1000
          roi_min_size: 0                 # minimum scale of a valid roi
          merger:
            type: retina
            kwargs:
              top_n: 100
              nms:
                type: naive
                nms_iou_thresh: 0.5
